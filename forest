import numpy as np
import pandas as pd
import seaborn as sns
from sklearn import datasets
iris = datasets.load_iris()
iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)
iris_df['Species'] = np.array([iris.target_names[cls] for cls in iris.target])
sns.pairplot(iris_df, hue='Species')
#ансамбль RandomForestClassifier, который позволяет решать задачу квалификации
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split
random_forest = RandomForestClassifier(n_estimators=100, random_state=42)
x_train, x_test, y_train, y_test = train_test_split(
iris.data, iris.target,
test_size=0.3, stratify=iris.target, random_state=42
)
rf_model = random_forest.fit(x_train, y_train)
#stratify при разбиении сохраняет распределение классов так, чтобы мы не обучались на данных, у которых нет какого-то одного класса, который появится в тестовой выборке

predictions = rf_model.predict(x_test)
print('Accuracy: {:.2f}'.format(accuracy_score(y_test, predictions)))
confusion_scores = confusion_matrix(y_test, predictions)
confusion_df = pd.DataFrame(confusion_scores, columns=iris.target_names,
index=iris.target_names)
sns.heatmap(confusion_df, annot=True)


feature_importance = list(zip(iris.feature_names, rf_model.feature_importances_))
feature_importance_df = pd.DataFrame(feature_importance,
columns=['Feature', 'RF Importance'])
feature_importance_df
rf_model.get_params()
